# This file contains default configuration file.
# !!! This file must not be modified !!!
# Custom configuration must be set in application.conf file.

# HTTP filters
play.filters {
  # name of cookie in which the CSRF token is transmitted to client
  csrf.cookie.name = THE-HIVE-XSRF-TOKEN
  # name of header in which the client should send CSRD token
  csrf.header.name = X-THe-HIVE-XSRF-TOKEN

  enabled = [
    org.elastic4play.services.EventFilter,
    org.elastic4play.services.TempFilter,
    global.CSRFFilter
  ]
}

# handler for errors (transform exception to related http status code
play.http.errorHandler = org.elastic4play.ErrorHandler

# Register module for dependency injection
play.modules.enabled += global.TheHive

play.http.session.cookieName = THE_HIVE_SESSION

# ElasticSearch
search {
  # Name of the index
  index = the_hive
  # Name of the ElasticSearch cluster
  cluster = hive
  # Address of the ElasticSearch instance
  host = ["127.0.0.1:9300"]
  # Scroll keepalive
  keepalive = 1m
  # Size of the page for scroll
  pagesize = 50
  # Number of shards
  nbshards = 5
  # Number of replicas
  nbreplicas = 1
}

# Datastore
datastore {
  name = data
  # Size of stored data chunks
  chunksize = 50k
  hash {
    # Main hash algorithm /!\ Don't change this value
    main = "SHA-256"
    # Additional hash algorithms (used in attachments)
    extra = ["SHA-1", "MD5"]
  }
  attachment.password = "malware"
}

auth {
	method {
		# basic authentication is disabled by default
		basic = false
		# authentication using API key
		key = true
		# authentication using a client x509 certificate
		pki = true
	}

	# "provider" parameter contains authentication provider. It is multi-valued (useful for migration)
	# available auth types are:
	# services.LocalAuthSrv : passwords are stored in user entity (in ElasticSearch). No configuration are required.
	# ad : use ActiveDirectory to authenticate users. Configuration is under "auth.ad" key
	# ldap : use LDAP to authenticate users. Configuration is under "auth.ldap" key
	provider = [local]
	
	ad {
		# Domain Windows name using DNS format. This parameter is required.
		#domainFQDN = "mydomain.local"
		
		# Domain Windows name using short format. This parameter is required.
		#domainName = "MYDOMAIN"
		
		# Use SSL to connect to domain controller
		#useSSL = true
	}
	
	ldap {
		# LDAP server name or address. Port can be specified (host:port). This parameter is required.
		#serverName = "ldap.mydomain.local:389"

		# Use SSL to connect to directory server
		#useSSL = true
		
		# Account to use to bind on LDAP server. This parameter is required.
		#bindDN = "cn=thehive,ou=services,dc=mydomain,dc=local"
		
		# Password of the binding account. This parameter is required.
		#bindPW = "***secret*password***"
		
		# Base DN to search users. This parameter is required.
		#baseDN = "ou=users,dc=mydomain,dc=local"
		
		# Filter to search user {0} is replaced by user name. This parameter is required.
		#filter = "(cn={0})"
	}
}

# Maximum time between two requests without requesting authentication
session {
  warning = 5m
  inactivity = 1h
}

# Streaming
stream.longpolling {
  # Maximum time a stream request waits for new element
  refresh = 1m
  # Lifetime of the stream session without request
  cache = 15m
}

# Name of the ElasticSearch type used to store dblist /!\ Don't change this value
dblist.name = dblist
# Name of the ElasticSearch type used to store audit event /!\ Don't change this value
audit.name = audit
# Name of the ElasticSearch type used to store attachment /!\ Don't change this value
datastore.name = data

akka {
  actor {
    provider = "cluster"
    serializers {
      stream = "services.StreamSerializer"
    }

    serialization-bindings {
      "services.StreamActorMessage" = stream
    }
  }
}
migration {
//  stream {
//    # Initial size of buffers used in stream elements
//    initial-input-buffer-size = 4
//    # Maximum size of buffers used in stream elements
//    max-input-buffer-size = 16
//
//    # Fully qualified config path which holds the dispatcher configuration
//    # to be used by ActorMaterializer when creating Actors.
//    # When this value is left empty, the default-dispatcher will be used.
//    dispatcher = ""
//
//    # Cleanup leaked publishers and subscribers when they are not used within a given
//    # deadline
//    subscription-timeout {
//      # when the subscription timeout is reached one of the following strategies on
//      # the "stale" publisher:
//      # cancel - cancel it (via `onError` or subscribing to the publisher and
//      #          `cancel()`ing the subscription right away
//      # warn   - log a warning statement about the stale element (then drop the
//      #          reference to it)
//      # noop   - do nothing (not recommended)
//      mode = cancel
//
//      # time after which a subscriber / publisher is considered stale and eligible
//      # for cancelation (see `akka.stream.subscription-timeout.mode`)
//      timeout = 5s
//    }
//
//    # Enable additional troubleshooting logging at DEBUG log level
//    debug-logging = off
//
//    # Maximum number of elements emitted in batch if downstream signals large demand
//    output-burst-limit = 1000
//
//    # Enable automatic fusing of all graphs that are run. For short-lived streams
//    # this may cause an initial runtime overhead, but most of the time fusing is
//    # desirable since it reduces the number of Actors that are created.
//    # Deprecated, since Akka 2.5.0, setting does not have any effect.
//    auto-fusing = on
//
//    # Those stream elements which have explicit buffers (like mapAsync, mapAsyncUnordered,
//    # buffer, flatMapMerge, Source.actorRef, Source.queue, etc.) will preallocate a fixed
//    # buffer upon stream materialization if the requested buffer size is less than this
//    # configuration parameter. The default is very high because failing early is better
//    # than failing under load.
//    #
//    # Buffers sized larger than this will dynamically grow/shrink and consume more memory
//    # per element than the fixed size buffers.
//    max-fixed-buffer-size = 1000000000
//
//    # Maximum number of sync messages that actor can process for stream to substream communication.
//    # Parameter allows to interrupt synchronous processing to get upsteam/downstream messages.
//    # Allows to accelerate message processing that happening withing same actor but keep system responsive.
//    sync-processing-limit = 1000
//
//    debug {
//      # Enables the fuzzing mode which increases the chance of race conditions
//      # by aggressively reordering events and making certain operations more
//      # concurrent than usual.
//      # This setting is for testing purposes, NEVER enable this in a production
//      # environment!
//      # To get the best results, try combining this setting with a throughput
//      # of 1 on the corresponding dispatchers.
//      fuzzing-mode = off
//    }
//
//    io.tcp {
//      # The outgoing bytes are accumulated in a buffer while waiting for acknoledgment
//      # of pending write. This improves throughput for small messages (frames) without
//      # sacrificing latency. While waiting for the ack the stage will eagerly pull
//      # from upstream until the buffer exceeds this size. That means that the buffer may hold
//      # slightly more bytes than this limit (at most one element more). It can be set to 0
//      # to disable the usage of the buffer.
//      write-buffer-size = 16 KiB
//    }
//  }
}